{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TextCaps.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "LgElUVgpWfGT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_shape = 28, 28, 1\n",
        "n_class = 10\n",
        "routings = 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kjId1aZDWS-y",
        "colab_type": "code",
        "outputId": "d760ed21-21b3-431e-809a-9aa01245dac3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ls3YdrY_WWBb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def load_tensor(fname, base='/gdrive/My Drive/Uni_MNIST/'):\n",
        "    return np.load(os.path.join(base, fname))    \n",
        "\n",
        "X_train, y_train = tuple(map(load_tensor, ['X_synth_Kannada.npy', 'y_synth_Kannada.npy']))\n",
        "X_test,  y_test  = tuple(map(load_tensor, ['X_test_Kannada.npy',  'y_test_Kannada.npy']))\n",
        "\n",
        "X_train, X_test  = (X_train / 255.0).astype(np.float32), (X_test / 255.0).astype(np.float32)\n",
        "y_train, y_test = to_categorical(y_train), to_categorical(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g1DFce5RI99Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "import keras.backend as K\n",
        "import keras\n",
        "import argparse\n",
        "from PIL import Image, ImageFilter\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.core import Activation, Flatten\n",
        "from keras.layers.convolutional import UpSampling2D, Conv2D, MaxPooling2D\n",
        "from keras.layers import Dense, Reshape\n",
        "from keras import layers, models, optimizers\n",
        "from keras import initializers, layers\n",
        "from keras import callbacks\n",
        "from keras import backend as K\n",
        "\n",
        "class Length(layers.Layer):\n",
        "    \"\"\"\n",
        "    Compute the length of vectors. This is used to compute a Tensor that has the same shape with y_true in margin_loss.\n",
        "    Using this layer as model's output can directly predict labels by using `y_pred = np.argmax(model.predict(x), 1)`\n",
        "    inputs: shape=[None, num_vectors, dim_vector]\n",
        "    output: shape=[None, num_vectors]\n",
        "    \"\"\"\n",
        "    def call(self, inputs, **kwargs):\n",
        "        return K.sqrt(K.sum(K.square(inputs), -1))\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape[:-1]\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(Length, self).get_config()\n",
        "        return config\n",
        "\n",
        "\n",
        "class Mask(layers.Layer):\n",
        "    \"\"\"\n",
        "    Mask a Tensor with shape=[None, num_capsule, dim_vector] either by the capsule with max length or by an additional \n",
        "    input mask. Except the max-length capsule (or specified capsule), all vectors are masked to zeros. Then flatten the\n",
        "    masked Tensor.\n",
        "    For example:\n",
        "        ```\n",
        "        x = keras.layers.Input(shape=[8, 3, 2])  # batch_size=8, each sample contains 3 capsules with dim_vector=2\n",
        "        y = keras.layers.Input(shape=[8, 3])  # True labels. 8 samples, 3 classes, one-hot coding.\n",
        "        out = Mask()(x)  # out.shape=[8, 6]\n",
        "        # or\n",
        "        out2 = Mask()([x, y])  # out2.shape=[8,6]. Masked with true labels y. Of course y can also be manipulated.\n",
        "        ```\n",
        "    \"\"\"\n",
        "    def call(self, inputs, **kwargs):\n",
        "        if type(inputs) is list:\n",
        "            assert len(inputs) == 2\n",
        "            inputs, mask = inputs\n",
        "        else: \n",
        "            x = K.sqrt(K.sum(K.square(inputs), -1))\n",
        "            mask = K.one_hot(indices=K.argmax(x, 1), num_classes=x.get_shape().as_list()[1])\n",
        "\n",
        "        masked = K.batch_flatten(inputs * K.expand_dims(mask, -1))\n",
        "        return masked\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        if type(input_shape[0]) is tuple:\n",
        "            return tuple([None, input_shape[0][1] * input_shape[0][2]])\n",
        "        else:\n",
        "            return tuple([None, input_shape[1] * input_shape[2]])\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(Mask, self).get_config()\n",
        "        return config\n",
        "\n",
        "\n",
        "def squash(vectors, axis=-1):\n",
        "    \"\"\"\n",
        "    The non-linear activation used in Capsule. It drives the length of a large vector to near 1 and small vector to 0\n",
        "    :param vectors: some vectors to be squashed, N-dim tensor\n",
        "    :param axis: the axis to squash\n",
        "    :return: a Tensor with same shape as input vectors\n",
        "    \"\"\"\n",
        "    s_squared_norm = K.sum(K.square(vectors), axis, keepdims=True)\n",
        "    scale = s_squared_norm / (1 + s_squared_norm) / K.sqrt(s_squared_norm + K.epsilon())\n",
        "    return scale * vectors\n",
        "\n",
        "class CapsuleLayer(layers.Layer):\n",
        "    \"\"\"\n",
        "    The capsule layer. It is similar to Dense layer. Dense layer has `in_num` inputs, each is a scalar, the output of the\n",
        "    neuron from the former layer, and it has `out_num` output neurons. CapsuleLayer just expand the output of the neuron\n",
        "    from scalar to vector. So its input shape = [None, input_num_capsule, input_dim_capsule] and output shape = \\\n",
        "    [None, num_capsule, dim_capsule]. For Dense Layer, input_dim_capsule = dim_capsule = 1.\n",
        "\n",
        "    :param num_capsule: number of capsules in this layer\n",
        "    :param dim_capsule: dimension of the output vectors of the capsules in this layer\n",
        "    :param routings: number of iterations for the routing algorithm\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, num_capsule, dim_capsule,channels, routings=3,\n",
        "                 kernel_initializer='glorot_uniform',\n",
        "                 **kwargs):\n",
        "        super(CapsuleLayer, self).__init__(**kwargs)\n",
        "        self.num_capsule = num_capsule\n",
        "        self.dim_capsule = dim_capsule\n",
        "        self.routings = routings\n",
        "        self.channels = channels\n",
        "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert len(input_shape) >= 3, \"The input Tensor should have shape=[None, input_num_capsule, input_dim_capsule]\"\n",
        "        self.input_num_capsule = input_shape[1]\n",
        "        self.input_dim_capsule = input_shape[2]\n",
        "        \n",
        "        if(self.channels!=0):\n",
        "            assert int(self.input_num_capsule/self.channels)/(self.input_num_capsule/self.channels)==1, \"error\"\n",
        "            self.W = self.add_weight(shape=[self.num_capsule, self.channels,\n",
        "                                            self.dim_capsule, self.input_dim_capsule],\n",
        "                                     initializer=self.kernel_initializer,\n",
        "                                     name='W')\n",
        "            \n",
        "            self.B = self.add_weight(shape=[self.num_capsule,self.dim_capsule],\n",
        "                                     initializer=self.kernel_initializer,\n",
        "                                     name='B')\n",
        "        else:\n",
        "            self.W = self.add_weight(shape=[self.num_capsule, self.input_num_capsule,\n",
        "                                            self.dim_capsule, self.input_dim_capsule],\n",
        "                                     initializer=self.kernel_initializer,\n",
        "                                     name='W')\n",
        "            self.B = self.add_weight(shape=[self.num_capsule,self.dim_capsule],\n",
        "                                     initializer=self.kernel_initializer,\n",
        "                                     name='B')\n",
        "        \n",
        "\n",
        "        self.built = True\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        inputs_expand = K.expand_dims(inputs, 1)\n",
        "        \n",
        "        inputs_tiled = K.tile(inputs_expand, [1, self.num_capsule, 1, 1])\n",
        "        \n",
        "        if(self.channels!=0):\n",
        "            W2 = K.repeat_elements(self.W,int(self.input_num_capsule/self.channels),1)\n",
        "        else:\n",
        "            W2 = self.W\n",
        "            \n",
        "        inputs_hat = K.map_fn(lambda x: K.batch_dot(x, W2, [2, 3]) , elems=inputs_tiled)\n",
        "\n",
        "        b = tf.zeros(shape=[K.shape(inputs_hat)[0], self.num_capsule, self.input_num_capsule])\n",
        "\n",
        "        assert self.routings > 0, 'The routings should be > 0.'\n",
        "        for i in range(self.routings):\n",
        "\n",
        "            c = tf.nn.softmax(b, axis=1)\n",
        "            outputs = squash(K.batch_dot(c, inputs_hat, [2, 2])+ self.B)\n",
        "\n",
        "            if i < self.routings - 1:\n",
        "                b += K.batch_dot(outputs, inputs_hat, [2, 3])\n",
        "\n",
        "        return outputs\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return tuple([None, self.num_capsule, self.dim_capsule])\n",
        "\n",
        "\n",
        "def PrimaryCap(inputs, dim_capsule, n_channels, kernel_size, strides, padding):\n",
        "    \"\"\"\n",
        "    Apply Conv2D `n_channels` times and concatenate all capsules\n",
        "    :param inputs: 4D tensor, shape=[None, width, height, channels]\n",
        "    :param dim_capsule: the dim of the output vector of capsule\n",
        "    :param n_channels: the number of types of capsules\n",
        "    :return: output tensor, shape=[None, num_capsule, dim_capsule]\n",
        "    \"\"\"\n",
        "    output = layers.Conv2D(filters=dim_capsule*n_channels, kernel_size=kernel_size, strides=strides, padding=padding,\n",
        "                           name='primarycap_conv2d')(inputs)\n",
        "    outputs = layers.Reshape(target_shape=[-1, dim_capsule], name='primarycap_reshape')(output)\n",
        "    return layers.Lambda(squash, name='primarycap_squash')(outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uFcWkLx1OUfB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "def margin_loss(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Marginal loss used for the CapsNet training\n",
        "    :param y_true: [None, n_classes]\n",
        "    :param y_pred: [None, num_capsule]\n",
        "    :return: a scalar loss value.\n",
        "    \"\"\"\n",
        "    L = y_true * K.square(K.maximum(0., 0.9 - y_pred)) + \\\n",
        "        0.5 * (1 - y_true) * K.square(K.maximum(0., y_pred - 0.1))\n",
        "\n",
        "    return K.mean(K.sum(L, 1))\n",
        "\n",
        "def train_generator(x, y, batch_size, shift_fraction=0.):\n",
        "    generator = ImageDataGenerator(\n",
        "        width_shift_range=shift_fraction,\n",
        "        height_shift_range=shift_fraction).flow(x, y, batch_size=batch_size)\n",
        "\n",
        "    while True:\n",
        "        x_batch, y_batch = generator.next()\n",
        "        yield ([x_batch, y_batch], [y_batch, x_batch])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "buhAqnFiLvuy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = layers.Input(shape=input_shape)\n",
        "\n",
        "conv1 = layers.Conv2D(filters=64, kernel_size=3, strides=1, padding='valid', activation='relu', name='conv1')(x)\n",
        "conv2 = layers.Conv2D(filters=128, kernel_size=3, strides=1, padding='valid', activation='relu', name='conv2')(conv1)\n",
        "conv3 = layers.Conv2D(filters=256, kernel_size=3, strides=2, padding='valid', activation='relu', name='conv3')(conv2)\n",
        "primarycaps = PrimaryCap(conv3, dim_capsule=8, n_channels=32, kernel_size=9, strides=2, padding='valid')\n",
        "digitcaps = CapsuleLayer(num_capsule=n_class, dim_capsule=16, routings=routings, channels=32,name='digitcaps')(primarycaps)\n",
        "\n",
        "out_caps = Length(name='capsnet')(digitcaps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b5LL3IbCLscw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y = layers.Input(shape=(n_class,))\n",
        "\n",
        "masked_by_y = Mask()([digitcaps, y])\n",
        "masked = Mask()(digitcaps) \n",
        "\n",
        "decoder = models.Sequential(name='decoder')\n",
        "decoder.add(Dense(input_shape=(None, 16*n_class), activation=\"relu\", units=7*7*32))\n",
        "decoder.add(Reshape((7, 7, 32)))\n",
        "decoder.add(BatchNormalization(momentum=0.8))\n",
        "decoder.add(layers.Conv2DTranspose(32, (3, 3), strides=(1, 1), padding='same', activation=\"relu\"))\n",
        "decoder.add(layers.Conv2DTranspose(16, (3, 3), strides=(2, 2), padding='same', activation=\"relu\"))\n",
        "decoder.add(layers.Conv2DTranspose(8,  (3, 3), strides=(2, 2), padding='same', activation=\"relu\"))\n",
        "decoder.add(layers.Conv2DTranspose(4,  (3, 3), strides=(1, 1), padding='same', activation=\"relu\"))\n",
        "decoder.add(layers.Conv2DTranspose(1,  (3, 3), strides=(1, 1), padding='same', activation=\"sigmoid\"))\n",
        "decoder.add(layers.Reshape(target_shape=input_shape, name='out_recon'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FchhGWr1LrUl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Models for training and evaluation (prediction)\n",
        "\"\"\"\n",
        "\n",
        "train_model = models.Model([x, y], [out_caps, decoder(masked_by_y)])\n",
        "eval_model = models.Model(x, [out_caps, decoder(masked)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9TIwoUVCJTjO",
        "colab_type": "code",
        "outputId": "aa1d95c9-fc6f-4902-aa5f-44e8f20ecf96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        }
      },
      "cell_type": "code",
      "source": [
        "train_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_6 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 26, 26, 64)   640         input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2 (Conv2D)                  (None, 24, 24, 128)  73856       conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv3 (Conv2D)                  (None, 11, 11, 256)  295168      conv2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "primarycap_conv2d (Conv2D)      (None, 2, 2, 256)    5308672     conv3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "primarycap_reshape (Reshape)    (None, 128, 8)       0           primarycap_conv2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "primarycap_squash (Lambda)      (None, 128, 8)       0           primarycap_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "digitcaps (CapsuleLayer)        (None, 10, 16)       41120       primarycap_squash[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "input_7 (InputLayer)            (None, 10)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "mask_5 (Mask)                   (None, 160)          0           digitcaps[0][0]                  \n",
            "                                                                 input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "capsnet (Length)                (None, 10)           0           digitcaps[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "decoder (Sequential)            (None, 28, 28, 1)    267937      mask_5[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 5,987,393\n",
            "Trainable params: 5,987,329\n",
            "Non-trainable params: 64\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "589CX807N7_i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_model.compile(optimizer=optimizers.Adam(lr=1e-3),\n",
        "                    loss=[margin_loss, 'mse'],\n",
        "                    loss_weights=[1., 0.392],\n",
        "                    metrics={'capsnet': 'accuracy'})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0kJkT6ABOgmh",
        "colab_type": "code",
        "outputId": "e658005e-23c3-4ca1-8939-4b1963855650",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "train_model.fit_generator(generator=train_generator(X_train, y_train, batch_size, shift_fraction=0.15),\n",
        "                          steps_per_epoch=int(X_train.shape[0] / batch_size),\n",
        "                          epochs=10,\n",
        "                          shuffle=True,\n",
        "                          validation_data=[[X_test, y_test], [y_test, X_test]],\n",
        "                          callbacks=[ModelCheckpoint('Kanada_capsule.h5', monitor='val_capsnet_acc', save_best_only=True, mode='max')]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "625/625 [==============================] - 88s 141ms/step - loss: 0.1590 - capsnet_loss: 0.1347 - decoder_loss: 0.0620 - capsnet_acc: 0.8423 - val_loss: 0.2478 - val_capsnet_loss: 0.2180 - val_decoder_loss: 0.0759 - val_capsnet_acc: 0.7266\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 85s 136ms/step - loss: 0.0454 - capsnet_loss: 0.0306 - decoder_loss: 0.0378 - capsnet_acc: 0.9655 - val_loss: 0.2262 - val_capsnet_loss: 0.1972 - val_decoder_loss: 0.0739 - val_capsnet_acc: 0.7461\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 85s 136ms/step - loss: 0.0347 - capsnet_loss: 0.0218 - decoder_loss: 0.0327 - capsnet_acc: 0.9750 - val_loss: 0.2206 - val_capsnet_loss: 0.1940 - val_decoder_loss: 0.0678 - val_capsnet_acc: 0.7547\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 87s 139ms/step - loss: 0.0289 - capsnet_loss: 0.0173 - decoder_loss: 0.0296 - capsnet_acc: 0.9795 - val_loss: 0.2210 - val_capsnet_loss: 0.1976 - val_decoder_loss: 0.0596 - val_capsnet_acc: 0.7656\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 85s 137ms/step - loss: 0.0258 - capsnet_loss: 0.0149 - decoder_loss: 0.0278 - capsnet_acc: 0.9825 - val_loss: 0.2425 - val_capsnet_loss: 0.2188 - val_decoder_loss: 0.0605 - val_capsnet_acc: 0.7281\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 85s 136ms/step - loss: 0.0238 - capsnet_loss: 0.0135 - decoder_loss: 0.0265 - capsnet_acc: 0.9839 - val_loss: 0.2142 - val_capsnet_loss: 0.1911 - val_decoder_loss: 0.0590 - val_capsnet_acc: 0.7516\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 87s 139ms/step - loss: 0.0223 - capsnet_loss: 0.0124 - decoder_loss: 0.0252 - capsnet_acc: 0.9850 - val_loss: 0.2332 - val_capsnet_loss: 0.2104 - val_decoder_loss: 0.0582 - val_capsnet_acc: 0.7422\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 86s 138ms/step - loss: 0.0209 - capsnet_loss: 0.0114 - decoder_loss: 0.0242 - capsnet_acc: 0.9862 - val_loss: 0.2378 - val_capsnet_loss: 0.2168 - val_decoder_loss: 0.0536 - val_capsnet_acc: 0.7242\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 85s 136ms/step - loss: 0.0197 - capsnet_loss: 0.0105 - decoder_loss: 0.0234 - capsnet_acc: 0.9875 - val_loss: 0.2253 - val_capsnet_loss: 0.2034 - val_decoder_loss: 0.0559 - val_capsnet_acc: 0.7516\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 85s 136ms/step - loss: 0.0189 - capsnet_loss: 0.0100 - decoder_loss: 0.0225 - capsnet_acc: 0.9878 - val_loss: 0.2183 - val_capsnet_loss: 0.1966 - val_decoder_loss: 0.0554 - val_capsnet_acc: 0.7656\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe48ebda7f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "metadata": {
        "id": "ObVr3D08eNtv",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title\n",
        "class Generator:\n",
        "\n",
        "    def __init__(self, model,data,args,samples_to_generate = 2):\n",
        "        \"\"\"\n",
        "        Generating new images \n",
        "        :param model: the pre-trained CapsNet model\n",
        "        :param data: a tuple containing training and testing data, like `((x_train, y_train), (x_test, y_test))`\n",
        "        :param args: arguments\n",
        "        :param samples_to_generate: number of new training samples to generate per class\n",
        "        \"\"\"\n",
        "        self.model = model\n",
        "        self.data = data\n",
        "        self.args = args\n",
        "        self.samples_to_generate = samples_to_generate\n",
        "        print(\"-\"*100)\n",
        "        \n",
        "        (x_train, y_train), (x_test, y_test), x_recon = self.remove_missclassifications()\n",
        "        self.data = (x_train, y_train), (x_test, y_test)\n",
        "        self.reconstructions = x_recon\n",
        "        self.inst_parameter, self.global_position, self.masked_inst_parameter = self.get_inst_parameters()\n",
        "        print(\"Instantiation parameters extracted.\")\n",
        "        print(\"-\"*100)\n",
        "        self.x_decoder_retrain,self.y_decoder_retrain = self.decoder_retraining_dataset()\n",
        "        self.retrained_decoder = self.decoder_retraining()\n",
        "        print(\"Decoder re-training completed.\")\n",
        "        print(\"-\"*100)\n",
        "        self.class_variance, self.class_max, self.class_min = self.get_limits()\n",
        "        self.generated_images,self.generated_labels = self.generate_data()\n",
        "        print(\"New images of the shape \",self.generated_images.shape,\" Generated.\")\n",
        "        print(\"-\"*100)\n",
        "\n",
        "    def save_output_image(self,samples,image_name):\n",
        "        \"\"\"\n",
        "        Visualizing and saving images in the .png format \n",
        "        :param samples: images to be visualized\n",
        "        :param image_name: name of the saved .png file\n",
        "        \"\"\"\n",
        "        if not os.path.exists(args.save_dir+\"/images\"):\n",
        "            os.makedirs(args.save_dir+\"/images\")\n",
        "        img = combine_images(samples)\n",
        "        img = img * 255\n",
        "        Image.fromarray(img.astype(np.uint8)).save(args.save_dir + \"/images/\"+image_name+\".png\")\n",
        "        print(image_name, \"Image saved.\")\n",
        "\n",
        "    def remove_missclassifications(self):\n",
        "        \"\"\"\n",
        "        Removing the wrongly classified samples from the training set. We do not alter the testing set.\n",
        "        :return: dataset with miss classified samples removed and the initial reconstructions.\n",
        "        \"\"\"\n",
        "        model = self.model\n",
        "        data = self.data\n",
        "        args = self.args   \n",
        "        (x_train, y_train), (x_test, y_test) = data\n",
        "        y_pred, x_recon = model.predict(x_train, batch_size=args.batch_size)\n",
        "        acc = np.sum(np.argmax(y_pred, 1) == np.argmax(y_train, 1))/y_train.shape[0]\n",
        "        cmp = np.argmax(y_pred, 1) == np.argmax(y_train, 1)\n",
        "        bin_cmp = np.where(cmp == 0)[0]\n",
        "        x_train = np.delete(x_train,bin_cmp,axis=0)\n",
        "        y_train = np.delete(y_train,bin_cmp,axis=0)\n",
        "        x_recon = np.delete(x_recon,bin_cmp,axis=0)\n",
        "        self.save_output_image(x_train[:100],\"original training\")\n",
        "        self.save_output_image(x_recon[:100],\"original reconstruction\")\n",
        "        return (x_train, y_train), (x_test, y_test), x_recon\n",
        "        \n",
        "        \n",
        "    def get_inst_parameters(self):\n",
        "        \"\"\"\n",
        "        Extracting the instantiation parameters for the existing training set\n",
        "        :return: instantiation parameters, corresponding labels and the masked instantiation parameters\n",
        "        \"\"\"\n",
        "        model = self.model\n",
        "        data = self.data\n",
        "        args = self.args\n",
        "        (x_train, y_train), (x_test, y_test) = data\n",
        "        if not os.path.exists(args.save_dir+\"/check\"):\n",
        "            os.makedirs(args.save_dir+\"/check\")\n",
        "        \n",
        "        if not os.path.exists(args.save_dir+\"/check/x_inst.npy\"):\n",
        "            get_digitcaps_output = K.function([model.layers[0].input],[model.get_layer(\"digitcaps\").output])\n",
        "\n",
        "            get_capsnet_output = K.function([model.layers[0].input],[model.get_layer(\"capsnet\").output])\n",
        "\n",
        "            if (x_train.shape[0]%args.num_cls==0):\n",
        "                lim = int(x_train.shape[0]/args.num_cls)\n",
        "            else:\n",
        "                lim = int(x_train.shape[0]/args.num_cls)+1\n",
        "\n",
        "            for t in range(0,lim):\n",
        "                if (t==int(x_train.shape[0]/args.num_cls)):\n",
        "                    mod = x_train.shape[0]%args.num_cls\n",
        "                    digitcaps_output = get_digitcaps_output([x_train[t*args.num_cls:t*args.num_cls+mod]])[0]\n",
        "                    capsnet_output = get_capsnet_output([x_train[t*args.num_cls:t*args.num_cls+mod]])[0]\n",
        "                else:\n",
        "                    digitcaps_output = get_digitcaps_output([x_train[t*args.num_cls:(t+1)*args.num_cls]])[0]\n",
        "                    capsnet_output = get_capsnet_output([x_train[t*args.num_cls:(t+1)*args.num_cls]])[0]\n",
        "                masked_inst = []\n",
        "                inst = []\n",
        "                where = []\n",
        "                for j in range(0,digitcaps_output.shape[0]):\n",
        "                    ind = capsnet_output[j].argmax()\n",
        "                    inst.append(digitcaps_output[j][ind])\n",
        "                    where.append(ind)\n",
        "                    for z in range(0,args.num_cls):\n",
        "                        if (z==ind):\n",
        "                            continue\n",
        "                        else:\n",
        "                            digitcaps_output[j][z] = digitcaps_output[j][z].fill(0.0)\n",
        "                    masked_inst.append(digitcaps_output[j].flatten())\n",
        "                masked_inst = np.asarray(masked_inst)\n",
        "                masked_inst[np.isnan(masked_inst)] = 0\n",
        "                inst = np.asarray(inst)\n",
        "                where = np.asarray(where)\n",
        "                if (t==0):\n",
        "                    x_inst = np.concatenate([inst])\n",
        "                    pos = np.concatenate([where])\n",
        "                    x_masked_inst = np.concatenate([masked_inst])\n",
        "                else:\n",
        "                    x_inst = np.concatenate([x_inst,inst])\n",
        "                    pos = np.concatenate([pos,where])\n",
        "                    x_masked_inst = np.concatenate([x_masked_inst,masked_inst])\n",
        "            np.save(args.save_dir+\"/check/x_inst\",x_inst)\n",
        "            np.save(args.save_dir+\"/check/pos\",pos)\n",
        "            np.save(args.save_dir+\"/check/x_masked_inst\",x_masked_inst)\n",
        "        else:\n",
        "            x_inst = np.load(args.save_dir+\"/check/x_inst.npy\")\n",
        "            pos = np.load(args.save_dir+\"/check/pos.npy\")\n",
        "            x_masked_inst = np.load(args.save_dir+\"/check/x_masked_inst.npy\")\n",
        "        return x_inst,pos,x_masked_inst\n",
        "    \n",
        "    def decoder_retraining_dataset(self):\n",
        "        \"\"\"\n",
        "        Generating the dataset for the decoder retraining technique with unsharp masking\n",
        "        :return: training samples and labels for decoder retraining \n",
        "        \"\"\"\n",
        "        model = self.model\n",
        "        data = self.data\n",
        "        args = self.args\n",
        "        x_recon = self.reconstructions\n",
        "        (x_train, y_train), (x_test, y_test) = data \n",
        "        if not os.path.exists(args.save_dir+\"/check\"):\n",
        "            os.makedirs(args.save_dir+\"/check\")\n",
        "        if not os.path.exists(args.save_dir+\"/check/x_decoder_retrain.npy\"):\n",
        "            for q in range(0,x_recon.shape[0]):\n",
        "                save_img = Image.fromarray((x_recon[q]*255).reshape(28,28).astype(np.uint8))\n",
        "                image_more_sharp = save_img.filter(ImageFilter.UnsharpMask(radius=1, percent=1000, threshold=1))\n",
        "                img_arr = np.asarray(image_more_sharp)\n",
        "                img_arr = img_arr.reshape(-1,28,28,1).astype('float32') / 255.\n",
        "                if (q==0):\n",
        "                    x_recon_sharped = np.concatenate([img_arr])\n",
        "                else:\n",
        "                    x_recon_sharped = np.concatenate([x_recon_sharped,img_arr])\n",
        "            self.save_output_image(x_recon_sharped[:100],\"sharpened reconstructions\")\n",
        "            x_decoder_retrain = self.masked_inst_parameter\n",
        "            y_decoder_retrain = x_recon_sharped\n",
        "            np.save(args.save_dir+\"/check/x_decoder_retrain\",x_decoder_retrain)\n",
        "            np.save(args.save_dir+\"/check/y_decoder_retrain\",y_decoder_retrain)\n",
        "        else:\n",
        "            x_decoder_retrain = np.load(args.save_dir+\"/check/x_decoder_retrain.npy\")\n",
        "            y_decoder_retrain = np.load(args.save_dir+\"/check/y_decoder_retrain.npy\")\n",
        "        return x_decoder_retrain,y_decoder_retrain\n",
        "    \n",
        "    def decoder_retraining(self):\n",
        "        \"\"\"\n",
        "        The decoder retraining technique to give the sharpening ability to the decoder \n",
        "        :return: the retrained decoder\n",
        "        \"\"\"\n",
        "        model = self.model\n",
        "        data = self.data\n",
        "        args = self.args\n",
        "        x_decoder_retrain, y_decoder_retrain = self.x_decoder_retrain,self.y_decoder_retrain\n",
        "        \n",
        "        decoder = eval_model.get_layer('decoder')\n",
        "        decoder_in = layers.Input(shape=(16*10,))\n",
        "        decoder_out = decoder(decoder_in)\n",
        "        retrained_decoder = models.Model(decoder_in,decoder_out)\n",
        "        if (args.verbose):\n",
        "            retrained_decoder.summary()\n",
        "        retrained_decoder.compile(optimizer=optimizers.Adam(lr=args.lr),loss='mse',loss_weights=[1.0])\n",
        "        if not os.path.exists(args.save_dir+\"/retrained_decoder.h5\"):\n",
        "            retrained_decoder.fit(x_decoder_retrain, y_decoder_retrain, batch_size=args.batch_size, epochs=20)\n",
        "            retrained_decoder.save_weights(args.save_dir + '/retrained_decoder.h5')\n",
        "        else:\n",
        "            retrained_decoder.load_weights(args.save_dir + '/retrained_decoder.h5')\n",
        "        \n",
        "        retrained_reconstructions = retrained_decoder.predict(x_decoder_retrain, batch_size=args.batch_size)\n",
        "        self.save_output_image(retrained_reconstructions[:100],\"retrained reconstructions\")\n",
        "        return retrained_decoder\n",
        "        \n",
        "    def get_limits(self):\n",
        "        \"\"\"\n",
        "        Calculating the boundaries of the instantiation parameter distributions\n",
        "        :return: instantiation parameter indices in the descending order of variance, min and max values per class\n",
        "        \"\"\"\n",
        "        args = self.args\n",
        "        x_inst = self.inst_parameter\n",
        "        pos = self.global_position\n",
        "        glob_min = np.amin(x_inst.transpose(),axis=1)\n",
        "        glob_max = np.amax(x_inst.transpose(),axis=1)\n",
        "        \n",
        "        if not os.path.exists(args.save_dir+\"/check\"):\n",
        "            os.makedirs(args.save_dir+\"/check\")\n",
        "        if not os.path.exists(args.save_dir+\"/check/class_cov.npy\"):\n",
        "            for cl in range(0,self.args.num_cls):\n",
        "                tmp_glob = []\n",
        "                for it in range(0,x_inst.shape[0]):\n",
        "                    if (pos[it]==cl):\n",
        "                        tmp_glob.append(x_inst[it])\n",
        "                tmp_glob = np.asarray(tmp_glob)\n",
        "                tmp_glob = tmp_glob.transpose()\n",
        "                tmp_cov_max = np.flip(np.argsort(np.around(np.cov(tmp_glob),5).diagonal()),axis=0)\n",
        "                tmp_min = np.amin(tmp_glob,axis=1)\n",
        "                tmp_max = np.amax(tmp_glob,axis=1)\n",
        "                if (cl==0):\n",
        "                    class_cov = np.vstack([tmp_cov_max])\n",
        "                    class_min = np.vstack([tmp_min])\n",
        "                    class_max = np.vstack([tmp_max])\n",
        "                else:\n",
        "                    class_cov = np.vstack([class_cov,tmp_cov_max])\n",
        "                    class_min = np.vstack([class_min,tmp_min]) \n",
        "                    class_max = np.vstack([class_max,tmp_max]) \n",
        "            np.save(args.save_dir+\"/check/class_cov\",class_cov)\n",
        "            np.save(args.save_dir+\"/check/class_min\",class_min)\n",
        "            np.save(args.save_dir+\"/check/class_max\",class_max)\n",
        "        else:\n",
        "            class_cov = np.load(args.save_dir+\"/check/class_cov.npy\")\n",
        "            class_min = np.load(args.save_dir+\"/check/class_min.npy\")\n",
        "            class_max = np.load(args.save_dir+\"/check/class_max.npy\")\n",
        "        return class_cov,class_max,class_min\n",
        "\n",
        "    def generate_data(self):\n",
        "        \"\"\"\n",
        "        Generating new images and samples with the data generation technique \n",
        "        :return: the newly generated images and labels\n",
        "        \"\"\"\n",
        "        data = self.data\n",
        "        args = self.args   \n",
        "        (x_train, y_train), (x_test, y_test) = data\n",
        "        x_masked_inst = self.masked_inst_parameter\n",
        "        pos = self.global_position\n",
        "        retrained_decoder = self.retrained_decoder\n",
        "        class_cov = self.class_variance\n",
        "        class_max = self.class_max\n",
        "        class_min = self.class_min\n",
        "        samples_to_generate = self.samples_to_generate\n",
        "        generated_images = np.empty([0,x_train.shape[1],x_train.shape[2],x_train.shape[3]])\n",
        "        generated_images_with_ori = np.empty([0,x_train.shape[1],x_train.shape[2],x_train.shape[3]])\n",
        "        generated_labels = np.empty([0])\n",
        "        for cl in range(0,args.num_cls):\n",
        "            count = 0\n",
        "            for it in range(0,x_masked_inst.shape[0]): \n",
        "                if (count==samples_to_generate):\n",
        "                    break\n",
        "                if (pos[it]==cl):\n",
        "                    count = count + 1\n",
        "                    generated_images_with_ori = np.concatenate([generated_images_with_ori,x_train[it].reshape(1,x_train.shape[1],x_train.shape[2],x_train.shape[3])])\n",
        "                    noise_vec = x_masked_inst[it][x_masked_inst[it].nonzero()]\n",
        "                    for inst in range(int(class_cov.shape[1]/2)):\n",
        "                        ind = np.where(class_cov[cl]==inst)[0][0]\n",
        "                        noise = np.random.uniform(class_min[cl][ind],class_max[cl][ind])\n",
        "                        noise_vec[ind] = noise\n",
        "                    x_masked_inst[it][x_masked_inst[it].nonzero()] = noise_vec\n",
        "                    new_image = retrained_decoder.predict(x_masked_inst[it].reshape(1,args.num_cls*class_cov.shape[1]))\n",
        "                    generated_images = np.concatenate([generated_images,new_image])\n",
        "                    generated_labels = np.concatenate([generated_labels,np.asarray([cl])])\n",
        "                    generated_images_with_ori = np.concatenate([generated_images_with_ori,new_image])\n",
        "        self.save_output_image(generated_images,\"generated_images\")\n",
        "        self.save_output_image(generated_images_with_ori,\"generated_images with originals\")\n",
        "        generated_labels = keras.utils.to_categorical(generated_labels, num_classes=args.num_cls)\n",
        "        if not os.path.exists(args.save_dir+\"/generated_data\"):\n",
        "            os.makedirs(args.save_dir+\"/generated_data\")\n",
        "        np.save(args.save_dir+\"/generated_data/generated_images\",generated_images)\n",
        "        np.save(args.save_dir+\"/generated_data/generated_label\",generated_labels)\n",
        "        return generated_images,generated_labels\n",
        "\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "def combine_images(generated_images, height=None, width=None):\n",
        "    num = generated_images.shape[0]\n",
        "    if width is None and height is None:\n",
        "        width = int(math.sqrt(num))\n",
        "        height = int(math.ceil(float(num)/width))\n",
        "    elif width is not None and height is None:  # height not given\n",
        "        height = int(math.ceil(float(num)/width))\n",
        "    elif height is not None and width is None:  # width not given\n",
        "        width = int(math.ceil(float(num)/height))\n",
        "\n",
        "    shape = generated_images.shape[1:3]\n",
        "    image = np.zeros((height*shape[0], width*shape[1]),\n",
        "                     dtype=generated_images.dtype)\n",
        "    for index, img in enumerate(generated_images):\n",
        "        i = int(index/width)\n",
        "        j = index % width\n",
        "        image[i*shape[0]:(i+1)*shape[0], j*shape[1]:(j+1)*shape[1]] = img[:, :, 0]\n",
        "    return image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tPfzOCXafy14",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from argparse import Namespace\n",
        "\n",
        "args = Namespace(batch_size=128,\n",
        "                 cnt=200,\n",
        "                 data_generate=True,\n",
        "                 epochs=10,\n",
        "                 lam_recon=0.392,\n",
        "                 lr=1e-3,\n",
        "                 lr_decay=0.9,\n",
        "                 num_cls=10,\n",
        "                 routings=3,\n",
        "                 samples_to_generate=10,\n",
        "                 save_dir='Kanada',\n",
        "                 shift_fraction=0.1,\n",
        "                 verbose=True,\n",
        "                 weights=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kYE323CVf7v6",
        "colab_type": "code",
        "outputId": "f68a261c-6b07-4928-d5fc-0411da91503d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "cell_type": "code",
      "source": [
        "imgen = Generator(model=eval_model,\n",
        "                  data=((X_train, y_train), (X_test, y_test)),\n",
        "                  args=args,\n",
        "                  samples_to_generate=args.samples_to_generate)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------------------------------------------\n",
            "original training Image saved.\n",
            "original reconstruction Image saved.\n",
            "Instantiation parameters extracted.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_8 (InputLayer)         (None, 160)               0         \n",
            "_________________________________________________________________\n",
            "decoder (Sequential)         (None, 28, 28, 1)         267937    \n",
            "=================================================================\n",
            "Total params: 267,937\n",
            "Trainable params: 267,873\n",
            "Non-trainable params: 64\n",
            "_________________________________________________________________\n",
            "retrained reconstructions Image saved.\n",
            "Decoder re-training completed.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "generated_images Image saved.\n",
            "generated_images with originals Image saved.\n",
            "New images of the shape  (100, 28, 28, 1)  Generated.\n",
            "----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}